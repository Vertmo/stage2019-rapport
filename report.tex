\documentclass{report}
\usepackage[a4paper, margin=1in]{geometry}

\usepackage[english]{babel}
\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{shorttoc}
\usepackage{longtable}
\usepackage{listings,xcolor}
\usepackage{caption}
\usepackage{mathpartir}

\input{albertlang}
\input{michelsonlang}

\title{Compiling a low-level language to Michelson}
\author{Basile Pesin,\\
  under the supervision of Bruno Bernardo,\\
  Nomadic Labs}

\begin{document}

\maketitle

\tableofcontents

\chapter*{Context}
\addcontentsline{toc}{chapter}{Context}

\section{The Tezos blockchain}

The Tezos ecosystem is centered around the Tezos blockchain. A blockchain is a decentralized database, usually focused on storing data about transactions made by it's users. Blockchains usually use a dedicated token, or cryptocurrency, to quantify these transactions. These currency, while they can't really (yet) be used to buy physical goods outside of the blockchain, can usually be exchanged for traditional government-established currencies, at varying rates. The currencies are often named the same as there related blockchains, and that's the case for Tezos (in the following report, I'll use ``Tezos'' for the blockchain, and ``tez'' (or ``XTZ'') for the related crypto-currency).\\

The Tezos blockchain, while currently an outsider compared to older, more successful blockchains (like Bitcoin or Ethereum), has several unique features that make it appealing. Namely, the chain gives token holders governance over the chain, being by using a proof-of-stake algorithm, or by allowing it's core protocol to be amended by votes of the community. More details on these features, which won't be discussed in this report, can be found in the Tezos White Paper~\cite{whitePaper}.

More to the point of this work, Tezos puts a strong emphasis on safety : the chain is implemented in OCaml, a statically typed programming language, which prevents some runtime errors. As we will see below, formal verification is also a focus on the work around the chain, and will be the focus of this report.

\section{The Michelson programming language}

Tezos, as well as allowing regular ``humans'' to create accounts (referred to as tz1 accounts), also allows users to run programs on the blockchain. These programs are often called ``smart contracts'', since most of them are used to automate transactions between two parties. Once the contract has been uploaded (originated) on the blockchain, it can then be called by any other account (being a human user or another smart-contract) by sending a transaction, containing at least a small amount of tez to cover processing fees, as well as the parameters of the contract. The contract itself holds a balance and can use it's tokens to forge it's own transactions.

The programming language used to write smart contracts for Tezos is called Michelson~\cite{michelsonwhitedoc}. Michelson is a statically typed stack-based programming language, meaning that the programmer has to explicitly manipulate the typed stack of the interpreter, using low level instructions. Examples of Michelson contracts (and there specification) are available in section \ref{contractsSpec}

As Michelson is a low level language, it can be very tedious to write: to manipulate the stack explicitly, the programmer needs to keep in mind the state of the stack at every point in the program (fortunately an emacs michelson-mode exists to display such information). The language was purposefully designed to be simple, which makes it easy to specify and proof specifications of programs, as we'll see below. However, it also makes writing smart-contracts in Michelson a bit tedious, and creates a barrier to entry for new programmers wanting to work in the Tezos ecosystem.

Since the Michelson interpreter is already part of the Tezos protocol (and can only be changed by amendment and vote of the community), it's a good base to build upon : creating higher-level programming language that would compile to Michelson would facilitate the writing of smart-contracts. To accomplish this goal, a first step will be to establish an intermediate programming language, Albert, abstracting away some of the low-level hurdles of Michelson (the stack manipulations in particular). To keep formal verification in mind, the Albert language semantics will be specified, and the compiler proved correct.

\chapter{The Mi-Cho-Coq framework}

The Mi-Cho-Coq project consists in a formalisation of Michelson's semantics, written in Coq. Coupled with a weakest-precondition calculation, it allows it's users to specify properties of Michelson programs, and to prove them using the Coq proof assistant. We'll see below a few proofs of relatively simple contracts.

\section{Proving the specification of smart-contracts}

\subsection{Weather insurance}
\label{contractsSpec}

The first contract we'll prove using Mi-Cho-Coq is the weather insurance contract. It's principle is simple : the contract is originated containing, in it's storage the addresses of two other accounts, a treshold of rain, and the public key of a third party oracle. The contract is also originated with a balance. At any point, the oracle can send an integer representing the actual level of rain, as well as it's signature. The contract then verifies that the signature is correct, and if it is, compares the level of rain with it's treshold : it then sends it's whole balance to one of the addresses saved in it's storage, depending on the level of rain relative to it's treshold.


\begin{lstlisting}[language=michelson]
parameter (pair (signature %received_sig) (nat :rain %rain_level));
storage (pair (pair (contract unit %under_addr)
                    (contract unit %over_addr))
              (pair (nat %rain_tresh) (key %weather_service_key)));
code { DUP; DUP;
       CAR; MAP_CDR{PACK ; BLAKE2B};
       SWAP; CDDDR;
       DIP {UNPAIR}; CHECK_SIGNATURE ; # Check if the data has been correctly signed
       ASSERT; # If signature is not correct, end the execution
       DUP; DUP; DUP; DIIIP{CDR}; # Place storage type on bottom of stack
       DIIP{CDAR};                # Place contracts below numbers
       DIP{CADR};   # Get actual rain
       CDDAR;         # Get rain threshold
       CMPLT; IF {CAR} {CDR};     # Select contract to receive tokens
       BALANCE; UNIT; TRANSFER_TOKENS; # Setup and execute transfer
       NIL operation; SWAP; CONS;
       PAIR };
\end{lstlisting}
Given the description above, we can easily give a specification of the contract. In the followings specifications, I'll note as ``preconditions'' the conditions that must be verified for the contract not to call \lstinline{FAIL} (or a related macro). The ``postconditions'' fully describe the new state of the storage at the end of the execution, as well as the potential generated operations.

{\small
\begin{longtable}{rl}
  \textbf{Preconditions}: & \texttt{SignatureCorrect}(weather\_service\_key, received\_sig)\\
  \textbf{Postconditions}: & new\_storage = storage\\
  & rain\_tresh $<$ rain\_level $\Rightarrow$ returned\_operations = [transfer\_tokens balance over\_addr]\\
  & rain\_tresh $\ge$ rain\_level $\Rightarrow$ returned\_operations = [transfer\_tokens balance under\_addr]\\
\end{longtable}}

Although this is a pretty simple specification that was pretty simple to prove, one point stands out : we only specify the production of the operations at the end of the contract, and not there effect (in this case, that the balance of the contract would be drained after any successful execution). This is because Mi-Cho-Coq only specifies the execution of the contract, and not the interactions exteriors to a single execution.

\subsection{Vote}

Another specified smart-contract is the Vote contract. As it's name implies, it allows users to vote for a candidate among a list set at origination. The contracts retains the number of votes towards each candidate. Any user can vote any number of time, but must send 5 tez (or $5000000\mu tez$) with each vote, otherwise the transaction is refused.

\begin{lstlisting}[language=michelson]
storage (map string int %candidates);
parameter string %chosen;
code { AMOUNT; PUSH mutez 5000000; COMPARE; GT;
       IF { FAIL } {};
       DUP; DIP { CDR; DUP }; CAR; DUP;
       DIP {
             GET; ASSERT_SOME;
             PUSH int 1; ADD; SOME
           };
       UPDATE; NIL operation; PAIR
     }
\end{lstlisting}

We can then specify this smart-contract as follows (\texttt{amount} refers to the quantity of $\mu tez$ sent by the caller for the transaction):
{\small
\begin{longtable}{rl}
  \textbf{Preconditions}: & \texttt{amount} $>$ 5000000\\
  & chosen $\in$ \texttt{Keys}(storage)\\
  \textbf{Postconditions}: & returned\_operations = [ ]\\
  & $\forall$ c, c $\in$ \texttt{Keys}(storage) $\iff$ c $\in$ \texttt{Keys}(new\_storage)\\
  & new\_storage[chosen] = storage[chosen] + 1\\
  & $\forall$ c $\in$ \texttt{Keys}(storage), c $\neq$ chosen $\Rightarrow$ new\_storage[c] = storage[c]
\end{longtable}}

Despite not looking much more complicated than the weather insurance smart contract, the specification of the vote smart-contract was slightly harder to prove. Indeed, in order to prove most of the postconditions, we had to prove a few lemmas on the map datastructure, and the relations between the functions ($mem$, $get$ and $update$) used to manipulate it. These lemmas were integrated in the library of Mi-Cho-Coq, and will most likely be useful to prove other contracts in the future.

%\subsection{List manipulations} TODO ?

\section{Tooling Michocott}

Michocott is an implementation of Mi-Cho-Coq, using the Ott~\cite{ottLang} programming language. From a set of grammar definitions and rules, Ott can generate typing and semantic rules for Coq (and other proof assistants), a menhir parser, as well as latex documentation.

\subsection{Documentation generation}

In order to adapt Ott to Michelson's needs, and especially the format of it's online documentation (\url{http://tezos.gitlab.io/mainnet/whitedoc/michelson.html}), which uses the ReStructuredText (reST) format, I added a reST output mode to Ott. Given the architecture of the Ott compiler, which separates frontend from backend pretty well, it was fairly easy to add a new RST backend.\\
To make the output practical for integrating pieces of the documentation with human-written text, I also added a mode allowing to generate one \textit{.rst} file per typing/semantic rule. The fragments can then be integrated into a single documentation page using the reST \texttt{.. include::} directive.\\

Another goal of automated document generation is to check that the typing and semantic rules specified in Michocott (and Mi-Cho-Coq) are indeed the same as the ones actually implemented in the Michelson interpreter running in the chain. In order to easily compare the two, we need a structured output which can be automatically generated from both Michocott and the interpreter. Luckily for us, on the interpreter side, we already have the start of a solution : Alexandre Doussot developped, for his own tool (try-michelson \url{https://gitlab.com/nomadic-labs/try-michelson}) a tool capable to parse the Michelson documentation (which, while not being automatically generated from the interpreter code, is kept updated and in check by the Tezos developers).

In order to complete the chain between the interpreter and Michocott, I added a JSON output to Ott. An example of the JSON output is as follows :
\lstset{
    string=[s]{"}{"},
    stringstyle=\color{blue},
    comment=[l]{:},
    commentstyle=\color{black},
}
\begin{lstlisting}
    {"op":"CDR",
      "ty":[{
         "name":"t_fun1_CDR",
         "premises":[],
         "conclusion":"CDR :: pair ty1 ty2 -> ty2"}],
      "semantics":[{
          "name":"bs_CDR",
          "premises":[],
          "conclusion":"CDR / ( Pair d d' ) : S => d' : S"}]
    },
\end{lstlisting}
The implementation of the output is unfortunately, highly specific to Michelson's need (in particular, it sorts and organize the rules according to the instruction they relate too), so it's very unlikely it will be merged into Ott proper, and will probably remain in a Nomadic-specific fork.

\subsection{Parser and lexer improvements}

In addition to it's specification and documentation capabilities, Ott can also, using the grammar rules defined for a language, generate both an Ocamllex lexer and a Menhir parser (only for OCaml, but a port to use the coq version of Menhir should be doable with minimal modifications). These functionalities however are still, in the main branch of Ott, a bit lackluster, and I proposed the following changes to fix some of the issues I encountered while using the lexer generation (these changes can be seen in this GitHub PR : \url{https://github.com/ott-lang/ott/pull/52})

\begin{itemize}
\item Order of the tokens : In order for the tokens to be correctly lexed, a token prefixing another must be placed after the longer token in the \textit{.mll} file : this is because OCamllex always select the first matching token it encounters, and therefore would always select the prefix if it was first in the list. Fortunately, it's sufficient to sort the tokens by decreasing length to solve this problem. More difficult is the problem of regular expressions that can be included in one another. I decided to simply place the metavars (which are most likely to use regex) at the end of the list; a better method could surely be implemented to construct topological sort of regex, but this would really complicate the program and the running time of Ott, for really small benefits.
\item Type conversion : Regarding the metavars, some of them are often used to define a token containing a value of a type different than string (typically, to parse integer or floats). The lexer generation didn't account for this, so I added a feature to automatically add a \texttt{string\_of\_XXX} conversion to the token lexing. The features get the relevant type from the metavar declaration in the Ott source file. As of this PR, I've only added the conversions \texttt{string\_of\_int}, \texttt{string\_of\_bool} and \texttt{string\_of\_float}, but it could be interesting allowing users to define and use their own conversion arbitrary conversion function (however, that would require some heavier modification of the code, and most likely be a really niche feature)
\item Location : Finally, I completed the calculations of lexer locations, which didn't update when uncountering a new line (``\textbackslash n'' character), because the call to \texttt{Lexing.new\_line lexbuf} was missing. This is a tiny change, but it allows for parsing error message to be correct and helpful.
\end{itemize}

\chapter{The Albert Programming Language}

\section{Overview}

Albert is a higher-level programming language than Michelson~\cite{albertProposal}. The main difference with Michelson is that, in Albert, the stack is abstracted by a record with named variables, which makes their manipulations easier. The variables in the main ``stack'' record are handled linearly, which means they are consumed when used, and must be explicitly duplicated if they need to be used twice. This reflects Michelson's behaviour, where values on the stack are indeed consumed by instructions using them.\\

The linear typing is handled by Albert's typing rules, which keeps tracks of the content of the stack (without it's ordering) at any point during the execution. For instance, below is a type of an instruction that assigns the value contained in a variable \texttt{foo} to a variable \texttt{bar}.

$$
\inferrule*
    { }
    { \Gamma \vdash bar = foo : \{ foo : ty \} @ rty \Rightarrow \{ bar : ty \} @ rty }
$$

    Where \texttt{rty} is the type of the other values contained in the stack, and \texttt{@} denotes the join operation for record types. It's important to note that the join operator is not a simple append, and is commutative. It's actually equivalent to the \texttt{merge} operation in MergeSort, with the fields of the record sorted by lexicographic order of the labels. This canonical form is also extended to record types, where fields must be sorted in lexicographic order for the type to be deemed ``well formed''.

The semantics of this simple assign operation mirrors it's typing (the \texttt{@} join operation used here is similar to the one used for record types).

$$
\inferrule*
    { }
    { E \vdash bar = foo / \{ foo = val \} @ rval \rightarrow \{ bar = val \} @ rval }
    $$

\subsection{Types}

In order to fully utilize the possibilities of Michelson, Albert implements all the basic types implemented by michelson, that is : \texttt{int}, \texttt{nat}, \texttt{mutez}, \texttt{timestamp} for numeric types, \texttt{string} and \texttt{bytes}. Albert also implements the same data structures as Michelson, \texttt{list}, \texttt{set} and \texttt{map}.
    
Moreover, Albert generalizes \texttt{pair} types with \texttt{record}, and \texttt{or}, \texttt{option} and \texttt{bool} by n-ary \texttt{variant} with arbitrary constructors. For ease of use, Albert also adds these specific types to it's core language, making them equivalent to the similar record type (for instance, \texttt{option ty} is equivalent to the variant \texttt{[None : unit | Some : ty]}).

\subsection{Example smart-contract}

Below is the classic vote smart-contract, rewritten in Albert. It's notable that although the code is clearly longer than the Michelson one, it's also more comprehensible from an imperative programming frame of mind.

\lstset{language=albert}
\begin{lstlisting}
type storage_ty = { threshold : mutez; votes: map string nat }

def vote :
   { store : storage_ty ; param : string } ->
   { operations : list operation ; out_storage : storage_ty } =

    (store0; store1) = dup store;
    threshold = store1.threshold;
    { car = threshold; cdr = threshold_copy } = dup threshold;
    ok = amount < threshold;
    match ok with
       True -> state = store0.votes ;
               { car = state0; cdr = state1 } = dup state;
               { car = param0; cdr = param1 } = dup param;
               prevote_option = state1[param1];
               prevote = assert_some prevote_option;
               one = 1;
               postvote = prevote + one;
               postvote = Some postvote;
               final_state = { state0 with param0 |-> postvote };
               out_storage = { votes = final_state; threshold = threshold_copy };
               operations = []
     | False ->
               failwith "you're so cheap!"
    end
\end{lstlisting}

Two difficulties still arise from writing an Albert contract, and create verbosity : first, the need to constantly assign every intermediate value to a variables, and second, the need to explicitly duplicate each resource the program has to use twice. These are unfortunately necessary in order to keep Albert's resource management close to Michelson's stack based management.

\section{Formal semantics}

I started my work on Albert by writing down the formal semantics of the language, mostly by following the typing rules. I'll give below the highlights of the rules.

\subsection{Bases of the language}

$$
\inferrule* [left=(instr\_assign)]
    { E \vdash rhs / val -> val' \\ E |- lhs / val' \rightarrow val'' }
    { E \vdash lhs = rhs / val \rightarrow val'' }
$$

Most of the language is actually based on the \texttt{lhs} = \texttt{rhs} assignment instruction (as seen above), which is necessary to ensure all calculated values are indeed named and stored. An Albert program therefore resembles a series of assignments, with the left-hand side being either a simple variable, or a record destructuring. It's important two notes that, since an instruction always manipulates a record (representing Michelson's stack) the input value of \lstinline{rhs} and output value of \lstinline{rhs} are necessarily records, while the value passed from \lstinline{rhs} to \lstinline{lhs} can be anything. We'll note below the formal semantics of these two left-hand sides.

$$
\inferrule* [left=(lhs\_var)]
    { }
    { E \vdash var / val \rightarrow \{ var = val \} }
$$

$$
\inferrule* [left=(lhs\_record)]
    { }
    { E \vdash \{ l_1 = x_1 ; .. ; l_n = x_n \} / \{ l_1 = val_1 ; .. ; l_n = val_n \} \rightarrow \{ x_1 = val_1 ; .. ; x_n = val_n \} }
$$

    Actual calculations are performed in the right-hand side of assignment instructions. Right-hand sides can first be a simple argument: either a constant value, a variable or a record constructed from variables; as arguments are called from \lstinline{rhs}, their input value is always a record (representing the stack).

$$
\inferrule* [left=(arg\_var)]
    { }
    { E \vdash_{arg} var / \{ var = val \} \rightarrow val }
$$
$$
\inferrule* [left=(arg\_val)]
    { }
    { E \vdash_{arg} val / \{\} \rightarrow val }
$$
$$
\inferrule* [left=(arg\_record)]
    { }
    { E \vdash_{arg} \{ l_1 = x_1 ; .. ; l_n = x_n \} / \{ x_1 = val_1 ; .. ; x_n = val_n \} \rightarrow \{ l_1 = val_1 ; .. ; l_n = val_n \} }
$$

$$
\inferrule* [left=(rhs\_arg)]
    { E \vdash_{arg} arg / val \rightarrow val' }
    { E \vdash_{rhs} arg / val \rightarrow val' }
$$

Right-hand sides can also be a function application (to arguments). Functions can either be primitives (for instance, the \lstinline{dup} instruction is represented as a function) or user-defined. A user defined function is found in the environment ($E$), and is simply seen as an instruction (as in Michelson, all functions are global).

$$
\inferrule* [left=(f\_fvar)]
    { fvar = instruction \in E \\ E \vdash_{ins} instruction / val \rightarrow val' }
    { E \vdash_{f} f / val \rightarrow val' }
$$
$$
\inferrule* [left=(f\_dup)]
    { }
    { E \vdash_{f} dup / val \rightarrow \{ car = val; cdr = val \} }
$$

$$
\inferrule* [left=(rhs\_app)]
    { E \vdash_{arg} arg / val \rightarrow val' \\ E |-_{funct} f / val' \rightarrow val'' }
    { E \vdash_{rhs} f arg / val \rightarrow val'' }
$$

Right-hand sides can also act directly on record, either by projection (taking a specific fields of the record by name) or by updating them (which of course consumes other values on the stack).

$$
\inferrule* [left=(rhs\_projection)]
    { \{ l = val \} @ rval = rval' }
    { E \vdash_{rhs} var.l / rval' \rightarrow val }
$$
$$
\inferrule* [left=(rhs\_update)]
    { \{ l_1 = val'_1 ; .. ; l_n = val'_n \} @ rval = rval'
    \\ \{ l_1 = val_1 ; .. ; l_n = val_n \} @ rval = rval''}
    { E \vdash_{rhs} \{ var\:with\:l_1 = var_1 ; .. ; l_n = var_n \} / \{ var = rval' ; var_1 = val_1 ; .. ; var_n = val_n \} -> rval'' }
$$

Right-hand sides also include most of the arithmetic operations on numerical data. I give here both the $+$ rule, and the $/mod$ rule, interesting in that it returns a pair containing the quotient and the remainder of the euclidean division. The $-$ and $\times$ rules are similar to the $+$ ones.

$$
\inferrule* [left=(rhs\_projection)]
    {  }
    { E \vdash_{rhs} (x_1 + x_2) / \{ x_1 = nv_1 ; x_2 = nv_2 \} \rightarrow nv_1 + nv_2 }
$$
$$
\inferrule* [left=(rhs\_update)]
    { }
    { E \vdash_{rhs} (x_1\:/mod\:x_2) / \{ x_1 = nv_1 ; x_2 = nv_2 \} \rightarrow \{ quotient = nv_1 / nv_2 ; remainder = nv_1 \% nv_2 \} }
$$

Apart from assignments, the instruction language is also completed with a few specific instructions : for instance, the \lstinline{drop} instruction, which behave similarly to the !DROP! instruction in Michelson. It's a bit less useful in Albert however, as useless variable existing in the main record is not an annoyance for the programmer, who can simply ignore it.

$$
\inferrule* [left=(rhs\_update)]
    { }
    { E \vdash_{ins} DROP var / \{ var = val \} \rightarrow \{ \} }
$$

The instructions are linked together as sequences of instructions. The sequence rule is the following:

$$
\inferrule* [left=(ins\_seq)]
    { E \vdash_{ins} I_1 / val \rightarrow val' \\
      E \vdash_{ins} I_2 / val' \rightarrow val'' }
    { E \vdash_{ins} I_1 ; I_2 / val \rightarrow val'' }
$$

This seems pretty straightforward; however, we quickly see that the input and output values used by instructions (which are record values representing the stack) are incomplete: as the current rules are laid out, the only variables in the stack present in $val$ are the one actually consumed by $I_1$, and the ones present in val' are therefore either the one produced by $I_1$, or the one consumed by $I_2$, which are not necessarily the same. We therefore need to add a new rule, to allow for the passed stack fragments to be completed by unused variables. We call this rule \texttt{frame}, and specify it below.

$$
\inferrule* [left=(ins\_seq)]
    { E \vdash_{ins} instruction / rval \rightarrow rval' \\
      rval @ rval'' = rval_1 \\
      rval' @ rval'' = rval_2 }
    { E \vdash_{ins} instruction / rval_1 \rightarrow rval_2 }
$$

This rule is, of course, mirrored in the typing of the instruction.

\subsection{Data structures}

\subsubsection{Variants}

As we've seen above, Albert's \texttt{variant} types generalize the \texttt{or}, \texttt{option} and \texttt{bool} types. Variants are therefore the dual of Records, with the caveat that it is not possible to construct an empty variant (by choice, as Michelson does not have an empty type it could correspond to). Variants offer two mains operations to the user : constructing a \texttt{variant} value using a constructor, and pattern-matching on a \texttt{variant} value.

Constructor are determined by a label, and applied (as a function) on a single value. When constructing a \texttt{variant} value, the user must indicate the full type of the variant value (meaning, all the different constructors and their types). This choice was made in order to simplify the work of the type-checker of Albert (since Albert is an intermediate language designed to be compiled for, and not for programs to be manually written for, this should not be too much of an issue for future users). Below is the typing rule for \texttt{variant} value and constructor application, as well as the related semantic rule.

$$
\inferrule* [left=(val\_constr)]
    { G \vdash_{val} val : ty \\ [ constructor : ty ] @ vty' = vty }
    { G \vdash_{val} (constructor\:val : vty) : vty }
$$

$$
\inferrule* [left=(f\_constr)]
    { [ constructor : ty ] @ vty' = vty }
    { G \vdash_{funct} constructor\:vty : ty \Rightarrow vty }
$$

$$
\inferrule* [left=(f\_constr)]
    { }
    { E \vdash_{funct} constructor\:vty / val \rightarrow (constructor\:val : vty) }
$$

Like records, variants have a ``canonical form'', where constructors are ordered by lexicographic order. Therefore, the \texttt{@} join relation used above behaves exactly like the one on records.

Pattern matching can be used on variants either as a right-hand side (in which case every branch will be a right-hand side) or as an instruction (and every branch will be an instruction). To simplify typing and compilation, the branches have to be ordered in this same canonical, lexicographic order. Again, this is a restriction for a human programmer, but pretty simple to overcome for a higher-level compiler. Below is the typing rule, as well as the semantic rules for the right-hand side version of the pattern matching (the instruction version is similar).

$$
\inferrule* [left=(rhs\_match)]
    { \{var : [ cons_1 : ty_1 | \ldots | cons_k : ty_k ]\} @ rty = rty' \\
      \{var_1 : ty_1\} @ rty = rty_1 \ldots \{var_k : ty_k\} @ rty = rty_k \\
      G \vdash_{rhs} rhs_1 : rty_1 \Rightarrow ty \ldots G \vdash_{rhs} rhs_k : rty_k \Rightarrow ty }
    { G \vdash_{rhs} match\:var\:with\:cons_1\:var_1 \rightarrow rhs_1 | \ldots | cons_k\:var_k \rightarrow rhs_k\:end : rty' \Rightarrow (constructor\:val : vty) }
$$

$$
\inferrule* [left=(rhs\_match\_found)]
    { E \vdash_{rhs} rhs / \{ var' = val' \} \rightarrow val }
    { E \vdash_{rhs} match\:var\:with\:cons\:var' \rightarrow rhs | <branches\_rhs> end / \{ var = (cons\:val' : vty) \} \rightarrow val }
$$

$$
\inferrule* [left=(rhs\_match\_next)]
    { cons \neq cons' \\
      E \vdash_{rhs} match\:var\:with\:branches_rhs\:end / \{ var = (cons\:val' : vty) \} \rightarrow val' }
    { E \vdash_{rhs} match\:var\:with\:cons'\:var' \rightarrow rhs | <branches\_rhs> end / \{ var = (cons\:val' : vty) \} \rightarrow val }
$$

While these rules seem pretty verbose, they are quite simple to explain: every branch should have the same type (in an environment where the pattern's \texttt{var} has the type related to the constructor). Evaluation of a match simply consists in evaluating the correct right-hand side (by typing, all the branches must be specified, so the match always succeed). By typing, we also see that every-branch of the pattern-matching must consume the exact same variables from the stack. This is a severe restriction which could be difficult to deal with while programming in Albert, but is necessary in order for the compiled Michelson program to be correctly typed. The right-hand side match is particularly constrained, since the program can't even \texttt{drop} unnecessary variables in a branch.

\subsubsection{Lists}

As in Michelson, Albert implements linked lists. The language first gives the user a few operation to construct list, either in extension or by \texttt{cons} operations.

$$
\inferrule* [left=(rhs\_list)]
    { }
    { E \vdash_{rhs} [ var_1 ; .. ; var_n ] / \{ var_1 = val_1 ; .. ; var_n = val_n \} -> [ val_1 ; .. ; val_n ] }
$$

$$
\inferrule* [left=(rhs\_cons)]
    { }
    { x_1 :: x_2 / \{ x_1 = val_1 ; x_2 = lval_2 \} -> val_1 :: lval_2 }
$$

More interestingly, programmers can also pattern-match on an empty or non-empty list (to mimic the !IF\_CONS! instruction of Michelson). As in the previously-described variant pattern-matching, list pattern-matching exists both as a right-hand side and an instruction (we show below the instruction version of the semantic rules, for a change).

$$
\inferrule* [left=(ins\_list\_match\_nil)]
    { \{ var = [] \} @ rval = rval' \\ E \vdash_{ins} I_1 / rval \rightarrow val }
    { E \vdash_{ins} match\:var\:with [] \rightarrow I_1 | var_1 :: var_2 \rightarrow I_2\:end / rval' \rightarrow val }
$$

$$
\inferrule* [left=(ins\_list\_match\_cons)]
    { \{ var_1 = val_1 :: tl \} @ rval = rval' \\ \{ var_1 = val_1 ; var_2 = tl \} @ rval = rval'' }
    { E \vdash_{ins} match\:var\:with [] \rightarrow I_1 | var_1 :: var_2 -> I_2\:end / rval' \rightarrow val }
$$

More specific to lists (and to maps, as we'll see) are the \lstinline{map} (as a right-hand-side) and \lstinline{for} (as an instruction) operations, which mirror the !ITER! instruction.

TODO

\subsubsection{Maps}

TODO

\section{Compiler to Mi-Cho-Coq}

With all these rules written down (plus the typing rules), we now have to write a compiler answering to this formal specification, that is a compiler that, from a well-typed Albert program, compiles to a well typed Michelson program, with the type and semantics of the Michelson program being equivalent to the those of the Michelson's program. In order to specify and prove these properties, we'll first have to define a relation between Albert's type and Michelson's type, as well as a relation between Albert's values and Michelson's values (as we'll see in \ref{alberteqmichelson}).

In order to be able to use a formal specification of Michelson (which is already written in Coq), we'll compile to Mi-Cho-Coq's AST. More specifically, we'll target Mi-Cho-Coq's untyped syntax, which can then be turned back into the typed syntax using Mi-Cho-Coq's typer (if the untyped program is well-typed of course).

\subsection{Equivalence between Albert and Michelson}
\label{alberteqmichelson}

\subsection{Compiling instructions}

\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

\bibliography{biblio}{}
\bibliographystyle{unsrt}
\addcontentsline{toc}{chapter}{Bibliography}

\end{document}
